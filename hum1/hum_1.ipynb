{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humanities Context—Lab 1 Guide\n",
    "\n",
    "\n",
    "## Instructions/Assignment\n",
    "\n",
    "#### Part 1: Cleaning Data\n",
    "There are a lot of tweets in this data set. The first thing you need to do is download the data set and then create a much smaller version to test your work on. Do this using your favorite text editor. When you’re done you should have two text files, one is the original and the other is a text file just like tweets.txt except it should only have information for 30 tweets. \n",
    "\n",
    "\n",
    "#### Part 2: Creating Dictionaries\n",
    "Write a function in Python that reads the smaller tweet file and creates a list of dictionaries. Each dictionary will represent one line of your file and will have the key-value pairs:\n",
    "\n",
    "- text: a string, the text of the tweet all in lowercase\n",
    "- time: a datetime object, date and time of the tweet\n",
    "- latitude: a float, the latitude of the tweet's location\n",
    "- longitude: a float, the longitude of the tweet's location\n",
    "\n",
    "Start by opening your abbreviated tweet file and then read each line. As you read the line, parse the line using split to access the information you need and create a dictionary. Add the dictionary to a list.\n",
    "\n",
    "\n",
    "#### What to Submit\n",
    "Submit the smaller of your two tweet files. It should be in the same format as the tweets.txt above. Also submit a notebook called hum_1.ipynb that has your function from part 2 in it. If you finish this on Thursday, no need to attend lab on Friday. You’ll still get the credit.  If you don’t finish by the end of lab on Friday, submit what you have.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide:\n",
    "\n",
    "**Steps:**   \n",
    "1. **Making tweets.txt**  \n",
    "If opening/accessing all_tweets.txt is giving you trouble I uploaded my 30 line tweets.txt that you can use. I also did a quick scrub for profanity on it.\n",
    "\n",
    "2. **Defining our goal/steps**   \n",
    "For each tweet (aka each line of tweets.txt) we want a dictionary whose entries are the tweet's time, text, latitude, and longitude. We also want a master list that holds the dictionaries for each tweet. The tricky part of this lab is how we parse the tweet from a single string into its constituent parts. The flow of the program can be written as follows:\n",
    " 1. Open file  \n",
    " 2. while you have not yet encounted the last line of the file, get the next line\n",
    " 3. Parse the line into discrete parts as required\n",
    " 4. For each tweet, load its relevant parts into a dictionary   \n",
    " 5. Append the dictionary to master list, which is what we will returned \n",
    " 6. Repeat 2-5 until the last line of the file is read in  \n",
    "\n",
    "3. **Splitting tweet into its components**  \n",
    "In the text file, the tweet is split around tabs, so we can split it into a list using `.split('\\t')`. The location (as a single \\[lat,long\\] string), time, and text are at indices 0, 2, and 3 respectively.  \n",
    "\n",
    "4. **Refining/parsing components**  \n",
    " 1. Longitude/latitude: Although it's never directly stated, the convention is that latitude is ordered first. We can split the location around the comma with `.split(',')` and then we can clean up the extra spaces and square brackets with `.strip('[] ')`\n",
    " \n",
    " 2. Text: We need to remove the trailing '\\n' from the text with `.rstrip('\\n')`, and to convert it to all lowercase with `.lower()`.  \n",
    " \n",
    " 3. Time: We need to convert the string date-time group into a datetime object (see step 5)\n",
    " \n",
    "5. **datetime object**   \n",
    "A datetime object is a type of object that is designed to store a particular date and time as its value, and make performing date and time relation operations easier. There are several ways to instantiate a datetime object, but notably it can parse an [ISO 8061](https://en.wikipedia.org/wiki/ISO_8601) formatted string into a datetime object. Fortunately, the tweet's date and time is already stored in ISO 8061 format. We can create our datetime object by using `datetime.datetime.fromisoformat(datetime_string)`. \n",
    " \n",
    "Final considerations/points of discussion: Dictionary mutability and why adding it to list before adding any values to the dictionary still works fine, and why placing it outside the loop would, despite working, just give us a list of the same dictionary repeated 30 times. \n",
    "\n",
    "\n",
    "## Additional Information\n",
    "\n",
    "Just some extra stuff you might find helpful if you have the time, but not strictly necesary for the lab. \n",
    "\n",
    "### datetime module\n",
    "\n",
    "The datetime module supplies **classes** for manipulating dates and times. While date and time arithmetic is supported, the focus of the implementation is on efficient attribute extraction for output formatting and manipulation.\n",
    "\n",
    "The classes define objects that are useful for operations related to dates and time. When we import the datetime module, we can instantiate those objects and access their methods to help perform those operations.\n",
    "\n",
    "#### datetime classes\n",
    "The datetime module defines 6 classes. For this lab, the only one we really need is datetime, but I've included the rest just for completeness.\n",
    "\n",
    "1. datetime.date:  \n",
    "An idealized naive date, assuming the current Gregorian calendar always was, and always will be, in effect. Attributes: year, month, and day.  \n",
    "2. datetime.time:  \n",
    "An idealized time, independent of any particular day, assuming that every day has exactly 24*60*60 seconds. (There is no notion of “leap seconds” here.) Attributes: hour, minute, second, microsecond, and tzinfo.  \n",
    "3. datetime.datetime:  \n",
    "A combination of a date and a time. Attributes: year, month, day, hour, minute, second, microsecond, and tzinfo.\n",
    "4. datetime.timedelta:   \n",
    "A duration expressing the difference between two date, time, or datetime instances to microsecond resolution.\n",
    "5. datetime.tzinfo:   \n",
    "An *abstract base class*. This should not/can not be instaniated directly. Instead, we use its *subclass* timezone \n",
    "6. datetime.timezone:  \n",
    "A class that implements the tzinfo abstract base class. Tracks the timezone as a fixed offset from the UTC. Used in time related objects in their timezone attribute to track the timezone.\n",
    "\n",
    "**Properties and constraints**\n",
    "Date, time, datetime, and timezone objects immutable, hashable, and may either be **aware** (can locate itself relative to other aware objects) or **naive** (does not contain enough information to unambiguously locate itself relative to other date/time objects). The datetime module defines two contraints, which are imported to your program along with the module, and which are used by the date and datetime classes to define the minimum and maximum allowable year.\n",
    "\n",
    "1. datetime.MINYEAR: Set to 1.  \n",
    "2. datetime.MAXYEAR: Set to 9999.\n",
    "\n",
    "\n",
    "**Source**: [Python's datetime documentation](https://docs.python.org/3/library/datetime.html)\n",
    "\n",
    "**Related Modules and Packages**\n",
    "\n",
    "[calendar](https://docs.python.org/3/library/calendar.html#module-calendar): Provides general calendar related functions.  \n",
    "\n",
    "[time](https://docs.python.org/3/library/time.html#module-time): Provides various time-related functions.\n",
    "\n",
    "[dateutil](https://dateutil.readthedocs.io/en/stable/): A **third party** library that extends the the functionality of datetime with more advanced features, including extended timezone and parsing support. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \"irene is on the way to meet  rochester http://t.co/07by3a4\" was said on 2011-08-28 19:03:27 at [43.102102240000001, -77.51810055].\n",
      "\n",
      " \"@cami219 hahaha i love you!\" was said on 2011-08-28 19:03:28 at [25.587980000000002, -80.393619999999999].\n",
      "\n",
      " \"i really can't stand to be in a  salon.. #ihatethesmell\" was said on 2011-08-28 19:03:28 at [38.318311029999997, -81.718020730000006].\n",
      "\n",
      " \"i'm at los trompos fco de montejo (mérida) http://t.co/44p4cob\" was said on 2011-08-28 19:03:28 at [21.030365, -89.641650999999996].\n",
      "\n",
      " \"@blessthefall yes! awakening! cant wait tto hhear whats for the soul\" was said on 2011-08-28 19:03:28 at [29.004319899999999, -81.387371099999996].\n",
      "\n",
      " \"i'm at corberstone pl @knob hill (evans) http://t.co/f2o2chn\" was said on 2011-08-28 19:03:29 at [33.550829, -82.190280999999999].\n",
      "\n",
      " \"work needs to fly by ... i'm so excited to see spy kids 4 with then love of my life ... arreic\" was said on 2011-08-28 19:02:36 at [41.298669629999999, -81.915329330000006].\n",
      "\n",
      " \"@lowkeypea smh\" was said on 2011-08-28 19:03:28 at [30.575059889999999, -91.200385089999997].\n",
      "\n",
      " \"@andy6lover4ever i don't even know... :/\" was said on 2011-08-28 19:03:29 at [36.220809940000002, -119.33957958000001].\n",
      "\n",
      " \"i'm at krauser's convenience store (825 south concourse, greenwood ave, cliffwood beach) http://t.co/ddqq2jz\" was said on 2011-08-28 19:03:30 at [40.444289599999998, -74.217741399999994].\n",
      "\n",
      " \"abc ecommerce llc seattle, wa our top-of-the-line ecommerce package has  http://t.co/fuyvrwy seattle internet products & services #coupon\" was said on 2011-08-28 19:03:30 at [47.594591000000001, -122.33322699999999].\n",
      "\n",
      " \"get out at 130 tomorrow\" was said on 2011-08-28 19:03:30 at [34.607309100000002, -92.372810830000006].\n",
      "\n",
      " \"#lmc (@ vino nuevo w/ 4 others) http://t.co/8fcw2io\" was said on 2011-08-28 19:03:30 at [31.720490999999999, -106.317931].\n",
      "\n",
      " \"i'm at circle k (13951 triskett avenue, west 140th, cleveland) http://t.co/cqk46vl\" was said on 2011-08-28 19:03:30 at [41.463416000000002, -81.789683999999994].\n",
      "\n",
      " \"my wife is lined up to see william shatner.  this is important to her.  #fanexpo\" was said on 2011-08-28 19:03:30 at [43.638958389999999, -79.384154730000006].\n",
      "\n",
      " \"i'm at nosh euro bistro w/ @bevgarvin @chefdat http://t.co/vrpvati\" was said on 2011-08-28 19:03:30 at [32.820174199999997, -96.802356900000007].\n",
      "\n",
      " \"“@acommittedfool: we got another #fool in twitter jail! free @a_pimpin_fool”&lt;= whaaat?! i feel another #kingsmasterpiece coming...\" was said on 2011-08-28 19:03:30 at [18.338824819999999, -64.944068920000007].\n",
      "\n",
      " \"я не понял, ураган вернулся? опять поднялся ветер и пошел дождь! http://t.co/xjx5g2m\" was said on 2011-08-28 19:03:30 at [40.57331868, -73.977012470000005].\n",
      "\n",
      " \"tracy freckleton skin care seattle, wa $10 off your first facial for new customers! http://t.co/bmrfgye seattle beauty & day spas #coupon\" was said on 2011-08-28 19:03:30 at [47.638719000000002, -122.407405].\n",
      "\n",
      " \"@abbsb45 you can't have cats either because i want to be able to visit you to. hahaha\" was said on 2011-08-28 19:03:30 at [46.159660500000001, -67.592540130000003].\n",
      "\n",
      " \"@tauxicbeauty im making breakfast!!!! want some #teamchef\" was said on 2011-08-28 19:03:31 at [35.205331999999999, -89.881319000000005].\n",
      "\n",
      " \"@tom_ladore ah good man lol\" was said on 2011-08-28 19:03:31 at [41.23718547, -73.060133030000003].\n",
      "\n",
      " \"i'm at zen buffet (945 w. huntington dr., at 5th ave., monrovia) http://t.co/ccbfxhd\" was said on 2011-08-28 19:03:30 at [34.1404268, -118.02022789999999].\n",
      "\n",
      " \"i'm at chase bank (4200 sunset blvd., green valley, henderson) http://t.co/pxgpsyb\" was said on 2011-08-28 19:03:31 at [36.071295999999997, -115.08171408].\n",
      "\n",
      " \"i'm at san joaquin certified farmers' market (4994 claremont ave, at yokuts ave, stockton) http://t.co/ndkwvdw\" was said on 2011-08-28 19:03:31 at [37.996999709999997, -121.30971551].\n",
      "\n",
      " \"nap time\" was said on 2011-08-28 19:03:31 at [42.107505099999997, -70.752221500000005].\n",
      "\n",
      " \"usual /:\" was said on 2011-08-28 19:03:31 at [42.252394199999998, -71.143159010000005].\n",
      "\n",
      " \"@glow_show my fault glo\" was said on 2011-08-28 19:03:31 at [36.728370560000002, -76.595683859999994].\n",
      "\n",
      " \"@mzstarrgasms s/o new follower!!!!\" was said on 2011-08-28 19:03:33 at [42.922256109999999, -85.591309010000003].\n",
      "\n",
      " \"if your into free food, beer & agave you need to sneak into the expo comida latina stat!!!  http://t.co/pc7ryew\" was said on 2011-08-28 19:03:33 at [32.70733362, -117.16033115].\n",
      "\n",
      " \"3 o'clock think i an going to have an omelet\" was said on 2011-08-28 19:03:33 at [39.631455520000003, -79.949541289999999].\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Samuel Weissmann\n",
    "spw2136\n",
    "2019-10-24\n",
    "'''\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "def parse_tweets(file_name):\n",
    "    dicts_li = []\n",
    "    fo = open(file_name,'r')\n",
    "    tweet = fo.readline()\n",
    "    \n",
    "    while tweet !='':\n",
    "        #setup\n",
    "        tweet_li = tweet.split('\\t') #list of tweet split around a tab-space (\\t)\n",
    "        coordinates = tweet_li[0].split(\",\") #splits coords into a list\n",
    "        tweet_di = {} #empty dict to which we will add the relevant parts of the tweet\n",
    "        dtg = dt.datetime.fromisoformat(tweet_li[2]) #get the datetime object based on the \n",
    "                                                     #tweet's date\n",
    "        \n",
    "        #add entries to dictionary\n",
    "        tweet_di['text'] = tweet_li[3].lower().rstrip(\"\\n\")\n",
    "        tweet_di['time'] = dtg\n",
    "        tweet_di['latitude'] = coordinates[0].strip(\"[] \")\n",
    "        tweet_di['longitude'] = coordinates[1].strip(\"[]] \")\n",
    "        \n",
    "        #add dictionary to list\n",
    "        dicts_li.append(tweet_di) #discussion point: Could be added right away before adding values and still work\n",
    "        \n",
    "        #update LCV\n",
    "        tweet = fo.readline()\n",
    "        tweet.rstrip()\n",
    "    \n",
    "    #close file, return value\n",
    "    fo.close()\n",
    "    return dicts_li\n",
    "\n",
    "#test program    \n",
    "results = parse_tweets('tweets.txt')\n",
    "for di in results:\n",
    "    print(\"\\n \\\"{}\\\" was said on {} at [{}, {}].\".format(di['text'],str(di['time']),di['latitude'],di['longitude']))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
